#+TITLE: ML SIG 2019 Task 2
#+OPTIONS: toc:nil
#+DATE:
#+latex_header: \usepackage{float}
#+latex_header: \usepackage{url}
#+latex_header: \hypersetup{colorlinks   = true,urlcolor     = blue,linkcolor    = blue,citecolor    = red}
- DEADLINE :: 20^{th} June 2019

* Introduction to Machine Learning Terminologies
Learn about the following terminologies:
- Accuracy, Precision and F-Score
- Curse of Dimensionality
- Bias Variance Tradoff
- Loss Functions

*** Resources
- [[http://www.r2d3.us/visual-intro-to-machine-learning-part-1/][Visual Introduction to Machine Learning Part 1]]
- [[http://www.r2d3.us/visual-intro-to-machine-learning-part-2/][Visual Introduction to Machine Learning Part 2]]
- [[http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/][Introduction to Curse of Dimensionality]]

*** Wikpedia Articles
- [[https://en.wikipedia.org/wiki/Accuracy_and_precision][Wikipedia Accuracy vs Precision]]
- [[https://en.wikipedia.org/wiki/Bias%25E2%2580%2593variance_tradeoff][Wikipedia Bias vs Variance]]
- [[https://en.wikipedia.org/wiki/Curse_of_dimensionality][Wikipedia Curse of Dimensionality]]



* Genetic Algorithms
** What are Genetic Algorithms?
- [[https://web.cs.ucdavis.edu/~vemuri/classes/ecs271/Genetic%2520Algorithms%2520Short%2520Tutorial.htm][UC Davis Introduction to Genetic Algorthms]]
- [[https://github.com/lmarti/evolutionary-computation-course][Evolutionary computation course (AEC 02 and 03 only)]]
- https://lethain.com/genetic-algorithms-cool-name-damn-simple/


- Reference/Additional Reading : [[./David_E_Goldberg.pdf][David Goldberg's Book on Genetic Algorithms and
  Soft Computing]]

* Task 1
** Merge this repository into your fork/clone
 [[https://help.github.com/en/articles/merging-an-upstream-repository-into-your-fork][Github Merging into fork]]
** Solve GA_task.ipynb notebook
Implement a GA to extremize a polynomial within range.

* Neural Networks
** Visualization:
Youtube videos  - good, intuitive, in-depth
https://youtu.be/aircAruvnKk

** Online e-book
http://neuralnetworksanddeeplearning.com/

** Neural network made by google - Can understand hyper-parameter tuning
[[http://playground.tensorflow.org][Tensorflow Playground]]

* Task 2
DEADLINE :: 20^{th} June 2019
** Solve fill and solve neural_net.py file
*** Resources:
- https://youtu.be/aircAruvnKk
- http://neuralnetworksanddeeplearning.com/
- http://playground.tensorflow.org

*** Instructions:
There are 11 TODOS in this python file
Fill each one of those appropriately and you will have a working neural network
Instructions and resources have been provided wherever possible.
The implementation may not be perfect, so feel free to point out any mistakes / ask any doubts

After completing the task, some of the things you could try are (optional):
-  Implement different cost functions (binary cross-entropy)
-  Implement different activation functions (tanh, ReLU, softmax)
-  Incorporate these changes in the neural netwok code so that you can select the loss / activation function
-  Play with the hyper-paramters!


* Genetic Algorithms and Neural Networks
Combining Genetic algorithms and neural networks
Read up on these resources as. Later we will ask you to implement something similar.
- https://github.com/yugrocks/Genetic-Neural-Network
- https://github.com/shahril96/neural-network-with-genetic-algorithm-optimizer
